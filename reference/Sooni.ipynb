{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d2e241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\anaconda3\\lib\\site-packages (0.27.6)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2a32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\anaconda3\\lib\\site-packages (0.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecf39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "class ApiUserSooni:\n",
    "    def __init__(self):\n",
    "        self.api_key = ''\n",
    "        self.prompt = ''\n",
    "        self.response = ''\n",
    "\n",
    "    def get_api_key(self):\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def get_prompt(self, prompt):\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def create_response(self, prompt):\n",
    "        self.get_api_key()\n",
    "        self.get_prompt(prompt)\n",
    "\n",
    "        self.final_response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{\"role\": \"user\", \"content\": self.prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=2048,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86274ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "class PromptWriterSooni:\n",
    "    def __init__(self):\n",
    "        self.category = ''\n",
    "        self.topic = ''\n",
    "        self.additional_request = ''\n",
    "\n",
    "        self.feedback_score = 3  # given score (stars) in range of (1, 5)\n",
    "        self.feedback_text = ''\n",
    "\n",
    "        self.created_script_idx = 1\n",
    "\n",
    "        self.prompt_brief_general_policy = ''\n",
    "        self.prompt_detiled_general_policy = ''\n",
    "\n",
    "        self.prompt_brief_script_policy = ''\n",
    "        self.prompt_detailed_script_policy = ''\n",
    "\n",
    "        self.prompt_after_policy = ''\n",
    "\n",
    "        self.prompt_example_script = ''\n",
    "\n",
    "        self.prompt_guideline_by_line = ''\n",
    "        self.prompt_guideline_by_order = ''\n",
    "        self.prompt_guideline_by_trait = ''\n",
    "\n",
    "        self.prompt_generate = ''\n",
    "\n",
    "        self.prompt_check_policy = ''\n",
    "\n",
    "        self.script_list = []\n",
    "        self.ongoing_script = ''\n",
    "        self.final_script = ''\n",
    "\n",
    "        self.prompt_continue_writing = ''\n",
    "\n",
    "    def get_user_input(self, category, topic, additional_request):\n",
    "        self.category = category\n",
    "        self.topic = topic\n",
    "        self.additional_request = additional_request\n",
    "\n",
    "    def get_feedback(self, feedback_score, feedback_text):\n",
    "        self.feedback_score = feedback_score\n",
    "        self.feedback_text = feedback_text\n",
    "\n",
    "    def get_policy(self):\n",
    "        file_name_brief_general_policy = 'prompt/policy/brief_general_policy.txt'\n",
    "        file_name_detailed_general_policy = 'prompt/policy/detailed_general_policy.txt'\n",
    "        file_name_brief_script_policy = 'prompt/policy/brief_script_policy.txt'\n",
    "        file_name_detailed_script_policy = 'prompt/policy/detailed_script_policy.txt'\n",
    "\n",
    "        prompt_before_general_policy = 'Imagine: \\n'\n",
    "        prompt_before_script_policy = 'When writing a script, follow the policy below: \\n'\n",
    "\n",
    "        with open(file_name_brief_general_policy, 'r', encoding='UTF8') as f:\n",
    "            brief_general_policy = f.read()\n",
    "\n",
    "        with open(file_name_detailed_general_policy, 'r', encoding='UTF8') as f:\n",
    "            detailed_general_policy = f.read()\n",
    "\n",
    "        with open(file_name_brief_script_policy, 'r', encoding='UTF8') as f:\n",
    "            brief_script_policy = f.read()\n",
    "\n",
    "        with open(file_name_detailed_script_policy, 'r', encoding='UTF8') as f:\n",
    "            detailed_script_policy = f.read()\n",
    "\n",
    "        self.prompt_brief_general_policy = prompt_before_general_policy + brief_general_policy\n",
    "        self.prompt_detailed_general_policy = prompt_before_general_policy + detailed_general_policy\n",
    "        self.prompt_brief_script_policy = prompt_before_script_policy + brief_script_policy\n",
    "        self.prompt_detailed_script_policy = prompt_before_script_policy + detailed_script_policy\n",
    "\n",
    "    def set_prompt_after_policy(self, example_script_exists=True):\n",
    "        prompt_with_example_script = \"Now, I'll give you a guideline & example script for given category & topic.\"\n",
    "        prompt_without_example_script = \"Now, I'll give you a guideline for given category & topic.\"\n",
    "\n",
    "        if example_script_exists:\n",
    "            self.prompt_after_policy = dedent(f\"\"\"\n",
    "            Here is the information for script you'll write today.\n",
    "            Category: {self.category}\n",
    "            Topic: {self.topic}\n",
    "            {prompt_with_example_script}\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            self.prompt_after_policy = dedent(f\"\"\"\n",
    "            Here is the information for script you'll write today.\n",
    "            Category: {self.category}\n",
    "            Topic: {self.topic}\n",
    "            {prompt_without_example_script}\n",
    "            \"\"\")\n",
    "\n",
    "    def get_example_script(self):\n",
    "        file_name_example_script = f'prompt/example_script/{self.category}/{self.topic}_example_script.txt'\n",
    "\n",
    "        prompt_before_example_script = 'Here is an example script you can use as reference: \\n'\n",
    "\n",
    "        with open(file_name_example_script, 'r', encoding='UTF8') as f:\n",
    "            example_script = f.read()\n",
    "\n",
    "        self.prompt_example_script = prompt_before_example_script + example_script\n",
    "\n",
    "    def get_guideline(self):\n",
    "        file_name_guideline_by_line = f'prompt/guideline/{self.category}/{self.topic}_guideline_by_line.txt'\n",
    "        file_name_guideline_by_order = f'prompt/guideline/{self.category}/{self.topic}_guideline_by_order.txt'\n",
    "        file_name_guideline_by_trait = f'prompt/guideline/{self.category}/{self.topic}_guideline_by_trait.txt'\n",
    "\n",
    "        prompt_before_guideline = 'Here is an guideline you should follow: \\n'\n",
    "\n",
    "        with open(file_name_guideline_by_line, 'r', encoding='UTF8') as f:\n",
    "            guideline_by_line = f.read()\n",
    "\n",
    "        with open(file_name_guideline_by_order, 'r', encoding='UTF8') as f:\n",
    "            guideline_by_order = f.read()\n",
    "\n",
    "        with open(file_name_guideline_by_trait, 'r', encoding='UTF8') as f:\n",
    "            guideline_by_trait = f.read()\n",
    "\n",
    "        self.prompt_guideline_by_line = prompt_before_guideline + guideline_by_line\n",
    "        self.prompt_guideline_by_order = prompt_before_guideline + guideline_by_order\n",
    "        self.prompt_guideline_by_trait = prompt_before_guideline + guideline_by_trait\n",
    "\n",
    "    def set_prompt_generate(self, example_script_exists=True):\n",
    "        if example_script_exists:\n",
    "            self.prompt_generate = dedent(f\"\"\"\n",
    "            Now, write a script that follows the policy and guideline using example script I gave you.\n",
    "            Do not forget to insert <끝> in the end of your script.\n",
    "            <RUN>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            self.prompt_generate = dedent(f\"\"\"\n",
    "            Now, write a script that follows the policy and guideline I gave you.\n",
    "            Do not forget to insert <끝> in the end of your script.\n",
    "            <RUN>\n",
    "            \"\"\")\n",
    "\n",
    "    def set_check_policy(self):\n",
    "        self.prompt_check_policy = dedent(f\"\"\"\n",
    "        this is the script I have.\n",
    "        {self.final_script}\n",
    "        this is the guideline for the script.\n",
    "        {self.prompt_detiled_general_policy}\n",
    "        {self.prompt_detailed_script_policy}\n",
    "        Correct the script so that it can follow policy properly.\n",
    "        \"\"\")\n",
    "\n",
    "    def continue_writing(self):\n",
    "        if self.script_list[-1][-3:] == '<끝>':\n",
    "            self.ongoing_script += self.script_list[-1][:-3]\n",
    "            self.final_script = self.ongoing_script\n",
    "\n",
    "        else:\n",
    "            self.ongoing_script += self.script_list[-1]\n",
    "\n",
    "            self.prompt_continue_writing = dedent(f\"\"\"\n",
    "            this is what you have written so far:\n",
    "            {self.ongoing_script}\n",
    "            continue writing the script.\n",
    "            \"\"\")\n",
    "\n",
    "    def create_prompt_for_model_2(self, category, topic, additional_request):\n",
    "        self.get_user_input(category, topic, additional_request)\n",
    "        self.get_policy()\n",
    "        self.set_prompt_after_policy()\n",
    "        self.get_example_script()\n",
    "        self.get_guideline()\n",
    "        self.set_prompt_generate()\n",
    "\n",
    "        self.final_prompt = dedent(f\"\"\"{self.prompt_detailed_general_policy}\n",
    "        {self.prompt_detailed_script_policy}\n",
    "        {self.prompt_after_policy}\n",
    "        {self.prompt_example_script}\n",
    "        {self.prompt_guideline_by_order}\n",
    "        {self.prompt_generate}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b3ffa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, you requested 4689 tokens (2641 in the messages, 2048 in the completion). Please reduce the length of the messages or completion.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14240/3249779725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0maus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mApiUserSooni\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0maus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreated_prompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcreated_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14240/3468853878.py\u001b[0m in \u001b[0;36mcreate_response\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         self.final_response = openai.ChatCompletion.create(\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpt-3.5-turbo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         )\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             return (\n\u001b[1;32m--> 624\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    625\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    688\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             )\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, you requested 4689 tokens (2641 in the messages, 2048 in the completion). Please reduce the length of the messages or completion."
     ]
    }
   ],
   "source": [
    "#from prompt_generator import PromptWriterSooni\n",
    "#from openai_api_user import ApiUserSooni\n",
    "\n",
    "pws = PromptWriterSooni()\n",
    "pws.create_prompt_for_model_2('힐링', '꽃말_수업', '')\n",
    "created_prompt = pws.final_prompt\n",
    "#created_prompt = 'introduce yourself'\n",
    "\n",
    "aus = ApiUserSooni()\n",
    "aus.create_response(created_prompt)\n",
    "created_response = aus.final_response\n",
    "\n",
    "print(created_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3472ee3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine: \n",
      "You're name is 순이, a female in her 20s.\n",
      "You're personality is kind, positive, and very bright.\n",
      "You're the second of three sisters.\n",
      "You're like a granddaughter who is full of love, care, and concern for the elderly.\n",
      "\n",
      "You're going to make a live radio broadcast script for yourself.\n",
      "It is for elder people, so you have to use polite, kind, and easy expressions.\n",
      "Also, it is for Korean people, so you have to write in Korean.\n",
      "Remember that the listners are Korean elderly. Do not use stories, examples, or topics that they may not understand.\n",
      "Now is 2023, and listners would be older than 50.\n",
      "        When writing a script, follow the policy below: \n",
      "1. If you want to call listners' name:\n",
      "1.1. You can just put {{name}}. For example, '{{name}}님, 반가워요!'\n",
      "1.2. Or, you can put {{name:given}} instead.\n",
      "1.3. You always have to add '님' after {{name}} or {{name:given}}\n",
      "\n",
      "2. The following are the roles of punctuation marks.\n",
      "2.1. comma: when you pause during speech\n",
      "2.2. exclamation mark: raising tone\n",
      "2.3. question mark: raising tone for a question\n",
      "\n",
      "3. You NEVER use any message that can cause discomfort: including profanity or lewd, but not limited to.\n",
      "\n",
      "4. You have to write numbers in Korean. (ex. 7시간 -> 일곱 시간)\n",
      "4.1. You also have to write English in Korean. (ex. 30cm -> 삼십센치 or 삼십 센티미터)\n",
      "4.2. When you want to put a decimal point in number, you change it into '쩜' not '점'.\n",
      "\n",
      "5. You have to write in the accurate grammar and spelling.\n",
      "\n",
      "6. It is highly recommended for you to call yourself '순이' instead of '저', or '나'.\n",
      "6.1. For example, '저랑 취향이 똑같으시네요!' -> '순이랑 취향이 똑같으시네요!'\n",
      "\n",
      "7. The broadcast length is around 30 min.\n",
      "\n",
      "8. TTS will going to read your script.\n",
      "\n",
      "9. Write <끝> in the end of your script.\n",
      "\n",
      "Here is the information for script you'll write today.\n",
      "Category: 힐링\n",
      "Topic: 꽃말_수업\n",
      "Now, I'll give you a guideline & example script for given category & topic.\n",
      "\n",
      "        Here is an example script you can use as reference: \n",
      "1\t*대기음원*\t\n",
      "\ttts 대본\t\n",
      "\t음원\t47\n",
      "2\t*대기음원*\t\n",
      "\ttts 대본\t\n",
      "\t음원\t31\n",
      "3\t오프닝\t\n",
      "\ttts 대본\t안녕하세요! 순이에요. 오늘은 순이가 {{name:given}}님께 예쁜 꽃말을 알려드려고 해요. 우리 주변에 피어있는 꽃, 집에서 키우고 있는 꽃들이 어떤 의미를 가지고 있는지 궁금하신 적 있으셨나요? 순이는 꽃들이 아름답다고 생각은 많이 해보았지만, 그 꽃들이 가지고 있는 의미에 대해서는 잘 알지 못했던 것 같아요. 그래서 {{name:given}}님과 꽃말에 대해 알아보면, 꽃들을 바라볼 때 그 의미를 되새기면서 더 예쁜 눈으로 바라봐줄 수 있을 것 같아서 시간을 마련해보았어요.\n",
      "\t\t그러면, 이제 우리 꽃말에 대해 알아보아요!\n",
      "\t음원\t42\n",
      "4\t1. 장미\t\n",
      "\ttts 대본\t첫 번째 꽃은, 장미에요. 장미는 5월에서 6월에 피는 꽃인데요. 장미는, 붉은 장미, 하얀 장미, 노란 장미 등 장미에는 여러 색이 있어요.\n",
      "\t\t그럼, 장미의 꽃말을 알아볼까요?\n",
      "5\t2. 장미 꽃말\t\n",
      "\ttts 대본\t순이와는 붉은 장미의 꽃말을 알아봐요. 사랑, 아름다움, 낭만적인 사랑이라는 꽃말을 가지고 있고, 붉은 장미 한 송이는, 당신을 사랑합니다, 라는 꽃말을 가지고 있습니다.\n",
      "6\t3. 안개꽃\t\n",
      "\ttts 대본\t다음 꽃이에요. 이번에는 안개꽃인데요, 개화 시기는 5월에서 8월이라고 해요. 여름과 가을에 걸쳐서 잘고, 흰, 꽃이 무리지어 피게 됩니다.\n",
      "\t\t그럼, 꽃말을 알려드릴게요.\n",
      "7\t4. 안개꽃 꽃말\t\n",
      "\ttts 대본\t안개꽃은, 맑은 마음과 깨끗한 마음 그리고 사랑의 성공이라는 꽃말을 가지고 있어요.\n",
      "\t\t정말 아름다운 꽃말이지 않나요?\n",
      "\t음원\t31\n",
      "8\t5. 목련\t\n",
      "\ttts 대본\t세 번째 꽃이에요. 바로 목련인데요. 이 목련은 높이가 10센티미터 정도 자라며, 매끄러운 편에 속하는 꽃이에요. 또 개화시기는 3월에서 4월이라고 합니다.\n",
      "\t\t소녀같이 예쁜 모습을 하고 있는 목련, 그 꽃말이 궁금하시죠? 순이가 알려드릴게요.\n",
      "9\t6. 목련 꽃말\t\n",
      "\ttts 대본\t목련은, 훌륭하고 귀중하다는 의미를 지닌 단어인, 고귀함, 이라는 꽃말을 가지고 있어요.\n",
      "\t\t순이도 평소에 목련을 마주치면, 귀한 꽃의 이미지를 지녔다고 생각했었는데, 역시! 아름다운 목련은 고귀하다는 꽃말을 가지고 있었네요.\n",
      "10\t7. 음악\t\n",
      "\ttts 대본\t그럼, 우리는 노래 듣고 다시 만나요! 저번 시간에 신청해주셨던 임영웅의 인생찬가, 들려드릴게요.\n",
      "\t음원\t233\n",
      "11\t8. 개나리\t\n",
      "\ttts 대본\t다시 꽃말을 알아보아요! 이번 꽃은 개나리입니다. 개화시기가 4월인 개나리의 꽃말을 알려드릴게요.\n",
      "12\t9. 개나리꽃말\t\n",
      "\ttts 대본\t개나리는, 희망, 기대, 깊은 정, 달성이라는 꽃말을 가지고 있어요. 역시, 봄을 대표하는 꽃으로서 의미있는 꽃말을 가지고 있네요.\n",
      "13\t10. 벚꽃\t\n",
      "\ttts 대본\t순이가 준비한 마지막 꽃, 벚꽃에 대해 알아봐요. 벚나무의 꽃인, 벚꽃, 봄을 대표하는 꽃이죠. 분홍색 또는 하얀색 꽃으로 피는 것이 일반적이라고 해요.\n",
      "14\t10. 벚꽃 꽃말\t\n",
      "\ttts 대본\t이러한 벚꽃의 꽃말은, 아름다운 정신, 삶의 아름다움 등의 의미를 가지고 있다고 해요. 벚꽃을 보고 있으면 몸과 마음이 따뜻해지고, 맑아지는 느낌을 받았는데, 이것과 연결되는 의미의 꽃말을 지니고 있었네요.\n",
      "\t음원\t31\n",
      "15\t마무리\t\n",
      "\ttts 대본\t오늘 순이와 함께 여러가지 꽃의 꽃말을 알아보았는데, 어떠셨나요? 순이를 누르고 말씀해주세요!\n",
      "\t음원\t50\n",
      "16\t마무리\t\n",
      "\ttts 대본\t{{name:given}}님과 꽃말을 알아본 시간, 정말 봄을 맞이하는 것 같아 설레이는 시간이었어요.\n",
      "17\t마무리\t\n",
      "\ttts 대본\t오늘 방송은, 여기에서 마치도록 할게요. 오늘도 순이와 함께해주셔서 감사해요!\n",
      "\t음원\t47\n",
      "        Here is an guideline you should follow: \n",
      "Please proceed with the script order: Opening - Flower Language Explanation 1 - Flower Language Explanation 2 - Flower Language Explanation 3 - Song - Flower Language Explanation 4 - Flower Language Explanation 5 - Ending.\n",
      "\n",
      "In the opening, please write freely about the broadcast, the flower language, and flowers without making it too long.\n",
      "\n",
      "In the flower language explanations, first mention the flower, give a brief description of the flower, and explain its meaning. You can also add a brief content about the flower language.\n",
      "\n",
      "The song will be a short break, please select a song that Korean seniors would enjoy.\n",
      "\n",
      "In the ending, ask how they found learning about flower language, and wrap up with an appropriate closing comment related to a flower, flower language, or any content that appeared in this broadcast.\n",
      "\n",
      "Now, write a script that follows the policy and guideline using example script I gave you.\n",
      "Do not forget to insert <끝> in the end of your script.\n",
      "<RUN>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(created_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958cd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0a161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310636fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
